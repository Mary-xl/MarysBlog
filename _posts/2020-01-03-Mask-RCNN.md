---
layout:     post
title:      "Mask R-CNN Digest"
subtitle:   Reading and Digest
date:       2020-01-03
author:     Mary Li
header-img: img/2019-10-15-bg.jpeg
catalog: true
tags: 
    -  deep learning
    -  paper digest 
---

## Segmentation (general)
[![lw0k8A.md.png](https://s2.ax1x.com/2020/01/04/lw0k8A.md.png)](https://imgchr.com/i/lw0k8A)
<center> [3] </center>

Not like object detection tasks where CNN output a feature map (embedding) can be used for object detection (encoding).
In segmentation, pixel level correspondence is also required. Thus information from lower level of feature maps is important
for accurate segmentation. Following this logic, the important points are:
(1) There need a decoding process (instead of embedding in detection) in order to maintain the spatial structure for segmentation.<br>
    -deconvolution, upsampling, unpooling, interpolation etc.
(2) Fusion and aggregation of feature layers to get both semantic info in deeper layers and accurate location info in shallow layers.<br>
    -skip connection, refine block, CRF
(3) Multi-scale for segmentation of objects of various sizes. <br>
    -FCN, HR-net etc.
    
    


[![ld2CT0.md.png](https://s2.ax1x.com/2020/01/04/ld2CT0.md.png)](https://imgchr.com/i/ld2CT0)

[![ld2u01.md.png](https://s2.ax1x.com/2020/01/04/ld2u01.md.png)](https://imgchr.com/i/ld2u01)

There are three main contributions of MASK-RCNN worth emphasising here:<br>
(1) The use of FPN <br> 
    --increase the accuracy of object detection for objects of various scales/sizes.<br>
(2) The introduction of ROI Align <br>
    --It replaces the ROI pooling to mitigate the accuracy losses in the two quantization processes:original image projection onto
    feature map for RoI extraction; the RoI pooling into same sizes for following FC in classification and bbox regression. Using RoI
    align without accuracy losses will benefit the mask generation since it requires more accurate location information for masks. For
    segmentation, pixel to pixel correspondence matters. <br>
(3) Mask branch <br>
    --It is a FCN. Using a FCN instead of fc layers in the detection branch is because a flattening process will loss the spatial structure
     information necessary to generate masks.
   
   

## 2. FPN+Resnet Backbone 
[![ldclHx.md.png](https://s2.ax1x.com/2020/01/04/ldclHx.md.png)](https://imgchr.com/i/ldclHx)
We start from the smallest feature map and work our way down to bigger ones, by upscale operations.In the diagram we can see that, the 
feature map generated by layer 2 is first subjected to 1 X 1 convolutions to bring down the number of channels to 256. This is then added 
element-wise to the up-sampled output from the previous iteration. All the outputs of this process are subjected to 3 X 3 convolution layer 
to create final 4 feature maps(P2, P3, P4, P5). The 5th feature map (P6) is generated from a max pooling operation from P5.
<center> [2] </center> <br>

## 3. RPN after FPN
[![ldWJeA.md.png](https://s2.ax1x.com/2020/01/04/ldWJeA.md.png)](https://imgchr.com/i/ldWJeA)
[![ldWYdI.md.png](https://s2.ax1x.com/2020/01/04/ldWYdI.md.png)](https://imgchr.com/i/ldWYdI)
<center> [2] </center>
Note that each feature layer generated by the FPN is passed separately through RPN and the later NMS process, until before the ROI align we 
need to concatenate all these region proposals and then put them into RoI align.

## 4. ROI Align

## 5. Mask branch after ROI align

The ROI align outputs are passed through a series of 3 X 3 convolutional layers, followed by ReLU, whose number of out channels of each layer 
and number of layers is a hyper parameter (for Resnet-50-FPN it is set to be (256,256,256,256)). For each detection, we get a output tensor of 
same dimensions as ROI align output.



## Reference
[2] https://medium.com/@fractaldle/mask-r-cnn-unmasked-c029aa2f1296
[3] www.julyedu.com