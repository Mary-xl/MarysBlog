---
layout:     post
title:      "RCNN (v5)"
subtitle:   Reading and Digest
date:       2019-10-26
author:     Mary Li
header-img: img/2019-10-15-bg.jpeg
catalog: true
tags: 
    -  deep learning
    -  paper digest 
---

_This is a paper digest from the classic paper for RCNN by [1]._

## 1. Excerpt

### Introduction

_This paper is the first to show that a CNN can lead to dramatically higher object detection performance on PASCAL VOC as compared
to systems based on simpler HOG-like features._<br>
<br>
_Instead, we solve the CNN localization problem by operating within the “recognition using regions” paradigm, 
which has been successful for both object detection and semantic segmentation. At test time, our method generates around 2000 category-independent region proposals for
the input image, extracts a fixed-length feature vector from each proposal using a CNN, and then classifies each region with category-specific linear SVMs. We use a simple tech-
nique (affine image warping) to compute a fixed-size CNN input from each region proposal, regardless of the region’s shape._<br>
<br>
_A second challenge faced in detection is that labeled data is scarce and the amount currently available is insufficient for training a large CNN. The conventional solution to this problem is to use unsupervised pre-training, 
followed by supervised fine-tuning. The second principle contribution of this paper is to show that supervised pre-training on a large auxiliary dataset (ILSVRC), followed by domain-specific fine-tuning on a small dataset (PASCAL), is an
effective paradigm for learning high-capacity CNNs when data is scarce._<br>

### Object detection with R-CNN
![Kyn5I1.png](https://s2.ax1x.com/2019/10/27/Kyn5I1.png)
<center>[2] </center>

#### Region proposal
_Feature extraction： Features are computed by forward propagating a mean-subtracted 227 × 227 RGB image through five convolutional layers and two fully connected layers._<br>
<br>
#### Training
_**Supervised pre-training**. We discriminatively pre-trained the CNN on a large auxiliary dataset._<br><br>
_**Domain-specific fine-tuning**. To adapt our CNN to the new task (detection) and the new domain (warped proposal windows), we continue stochastic gradient descent (SGD)
training of the CNN parameters using only warped region proposals. Aside from replacing the CNN’s ImageNet-specific 1000-way classification layer with a randomly initialized (N + 1)-way classification layer (where N is the
number of object classes, plus 1 for background), the CNN architecture is unchanged._<br><br>
_We treat all region proposals with ≥ 0.5 IoU overlap with a ground-truth box as positives for that box’s class and the rest as negatives. We start SGD at
a learning rate of 0.001 (1/10th of the initial pre-training rate), which allows fine-tuning to make progress while not clobbering the initialization. In each SGD iteration, we uni-
formly sample 32 positive windows (over all classes) and 96 background windows to construct a mini-batch of size 128. We bias the sampling towards positive windows be-
cause they are extremely rare compared to background._ <br><br>
_**Object category classifiers**.  We resolve this issue with an IoU overlap threshold, below which regions are defined as negatives. The overlap threshold, 0.3,
was selected by a grid search over {0, 0.1, . . . , 0.5} on a validation set. Once features are extracted and training labels are applied, we optimize one linear SVM per class._<br>

#### Ablation studies
_Performance layer-by-layer, with fine-tuning. The improvement is striking: fine-tuning increases mAP by 8.0 percentage points to 54.2%. The boost from fine-tuning is
much larger for fc 6 and fc 7 than for pool 5 , which suggests that the pool 5 features learned from ImageNet are general and that most of the improvement is gained from learning
domain-specific non-linear classifiers on top of them._

#### Bounding-box regression
_We use a simple bounding-box regression stage to improve localization performance. After scoring each selective search proposal with a class-specific detection SVM,
we predict a new bounding box for the detection using a class-specific bounding-box regressor.The primary difference between the two
approaches is that here we regress from features computed by the CNN, rather than from geometric features computed on the inferred DPM part locations._ <br>
_The input to our training algorithm is a set of N training pairs {(P i , G i )} i=1,...,N , where P i = (P x i , P y i , P w i , P h i )
specifies the pixel coordinates of the center of proposal P i ’s bounding box together with P i ’s width and height in pixels. We parameterize the transformation in terms of four
functions d x (P ), d y (P ), d w (P ), and d h (P ).The first two specify a scale-invariant translation of the center of P ’s bounding box, while the second two specify log-space
translations of the width and height of P ’s bounding box. After learning these functions, we can transform an input proposal P into a predicted ground-truth box Ĝ by apply-
ing the transformation:_<br>
![Kyuowj.png](https://s2.ax1x.com/2019/10/27/Kyuowj.png)
<center> [1] </center>
![KyuTTs.png](https://s2.ax1x.com/2019/10/27/KyuTTs.png)
<center> [1] </center>

## 2. Related questions and discussion 

**Q1. Under what circumstances this algorithm been proposed?** 
<br>
It has been proposed at a time when object detection was mainly performed based on manual-features, such as SIFT and HOG. Such a method make the mAP increased very slowly.  <br>
For multi-object detection and localisation, the  mainly approaches are: (1) sliding window (2) bbox regression. <br>
In 2012, Hinton and his students used Alexnet to show the world how powerful is CNN. This shed light on the invention of RCNN. <br>
Meanwhile, it is not long after ReLU, normalization and dropout  been invented. This paper used all these cutting-edge techniques and achieved great success. <br>
While it is so interesting to look back in 2019, a take-away message for researchers is to always stand on the frontline.

**Q2. What is NMS?** 
<br>
Non-max suppression. It is very important operation that has been widely used in the field of computer vision, from the early Canny edge detection, to this recent RCNN. It has
basically been used in selecting the best candidate (max-score) while reducing the chances of redundant selection of the same object but slightly lower scores.
<br>
Code speaks better than words :): <br>
[![Kg3jqx.md.png](https://s2.ax1x.com/2019/10/28/Kg3jqx.md.png)](https://imgchr.com/i/Kg3jqx)

**Q3. The influence of fine-tune on backbone layers** 
<br>
The author used a pre-trained CNN (Alexnet/VGG16) as backbone. Not like the current trend of integrating the backbone into a big network and used pre-trained weights 
from large datasets as initialization and fine-tune end-to-end on local datasets, in that year due to the limitation of computation power and knowledge about a CNN's power as a feature extractor, here the author
used CNN as a standalone feature extractor.The author remove the last output layer from pre-trained model (eg.Alexnet FC8) and retain the FC6, FC7 in the fine-tuning process.
Its 4096 dimentional results are then put into SVM for further classification. Interestingly, they also made a comparison between with/without fine tuning on different layers:
[![Mj1zb6.md.png](https://s2.ax1x.com/2019/11/25/Mj1zb6.md.png)](https://imgchr.com/i/Mj1zb6)
<center> [1] </center>
![Mj39UO.png](https://s2.ax1x.com/2019/11/25/Mj39UO.png)
<center> [1] </center>
<br>

**Q3. Different choice of positive and negative samples in CNN fine-tuning and SVM training**
As mentioned in the paper, there are 3 training processes on local datasets:
![MviPKJ.png](https://s2.ax1x.com/2019/11/25/MviPKJ.png)
<center> [1] </center>

Both CNN fine-tuning and SVM are trained on local dataset with the same aim of classification. But the choice of positive and negative samples in CNN fine-tuning is much softer than that of SVM training. More specifically,
in CNN fine-tuning, any proposals with IoU>=0.5 are labeled as positive and the rest as negative. In SVM, only ground truth are used as positive and any proposals with IoU<=0.3 are used as negative.
The main reason is that CNN fine-tuning requires more dataset in training to avoid overfitting, while SVM is happy with small dataset in training. It leads to a result that the softmax output from CNN is not as accurate as 
the output of SVM, but only used as input for these SVM.



## Reference
[1] R. Girshick, J. Donahue, T. Darrell, and J. Malik.  Rich feature hierarchies for accurate object detectionand semantic segmentation. InCVPR, 2014. <br>
[2] https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e