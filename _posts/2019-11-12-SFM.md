---
layout:     post
title:      3D Reconstruction- SFM 
date:       2019-10-12
author:     Mary Li
header-img: img/2019-10-12-bg.png
catalog: true
tags: 
    -  3D mapping and reconstruction
    -  image processing 
---
_This article attempts to look into the technical details of SFM and summarise its workflow as well as discuss their pros/cons.Please contact the author if you need
to use any information from this article._

## Introduction
Structure from Motion technique serves as the building block for dense reconstruction. Since initially both camera poses and 3D points are unknowns 
it is a fundamentally ill-posed chicken-egg problem. In other words we can’t just throw them into an optimisation system for a quick answer (nonconvex optimization problems). 
Therefore we try to approach the SFM problem with a two step process: first get a good initial estimate, and then incrementally increase the size and accuracy of the system for optimization.

The general procedure is as following:
 1) Feature-based image matching; 
 2) pick one initial pair of matched images/views and calculate their relative geometry;
 3) from this pair calculates tracks (3D points) ; 
 4) do a bundle adjustment based on these 3D points and camera relative geometry for optimization; 
 5) incrementally adding new images/views into the system and repeat the bundle adjustment optimization process; 
 6) dense image matching and reconstruction.

## Methodology
### 1.Feature-based image matching

Image collection is first performed. Two typical scenarios:
- Un-ordered images collected by different cameras&poses&time, such as photos from social media site taken by tourists. 
It means camera intrinsic parameters are unknown (in some cases the k1,k2 are initialized to be 0 while f is obtained from the exif info).
- Images collected by using a single camera moving around the object to be reconstructed. Camera can be calibrated beforehand and camera intrinsic parameters K is known.

After image collection (Feature-based image matching such like SIFT,SURF, ORB etc,), feature extraction and matching are performed.

### 2. Initialise one image pair
#### 2.1 Pick the initial image pair

From all the matching image pairs pick one satisfy the following conditions:
(1) Enough matching points (>50 for instance) , the more the better;
(2) long baseline;
(3) Using RANSAC to build homography test and here less inlier is what we after. Why? Pure camera rotation will satisfy homography. It has been used for image mosaic generation,  but it can’t do SFM (camera shift is minimum requirement). We therefore need to avoid such pairs;
(4) Successfully triangulate more than half of the matched points (explained in the following).

#### 2.2 Calculate two view geometry
For this particular pair, its relative geometry is calculated:

-Suppose one camera coordinate system (one on the left in our example) overlaps with the world frame, calculate the Fundamental Matrix F based on at least 8 matching points (Eight-Point-Algorithm). Useing RANSAC with  Eight Point and least squares if outlier present.

Given one pair of matched 2D image points (x1, x2):
![Screenshot from 2019-10-15 14-53-41.png](https://i.loli.net/2019/10/15/chjfR6O42HDdlKo.png)
Due to epipole constrait: $x_2^TFx_1=0$.
![K9LyUe.png](https://s2.ax1x.com/2019/10/15/K9LyUe.png)

For a single pair of correspondence:
![K9j3Hf.png](https://s2.ax1x.com/2019/10/15/K9j3Hf.png)
For 8 dof in F, one point pairs provide one constraint.

For n correspondences:
![K9jGE8.png](https://s2.ax1x.com/2019/10/15/K9jGE8.png)

If n=8, one solution of F can be found;
if n>8, least squares solution can be used to provide the best estimate of F. 

-Given the intrinsic parameters of the two cameras (K1,K2), Essential Matrix E can be calculated:
![K9jOxA.png](https://s2.ax1x.com/2019/10/15/K9jOxA.png)

-With Essential Matrix, camera relative R and T can be calculated.
[![K9jjKI.png](https://s2.ax1x.com/2019/10/15/K9jjKI.png)](https://imgchr.com/i/K9jjKI)
Note here from the 4 possibilities, the one with P in front of both cameras is the right choice.
![K9jvrt.png](https://s2.ax1x.com/2019/10/15/K9jvrt.png)


#### 2.3 Calculate tracks using triangulation 
With this initial camera pair’s pose information and detected 2D image feature points, these 2D points’ 
3D coordinates can be calculated by triangulation:

![KCnBsP.png](https://s2.ax1x.com/2019/10/15/KCnBsP.png)
![KCnydS.png](https://s2.ax1x.com/2019/10/15/KCnydS.png)
![KCnDqf.png](https://s2.ax1x.com/2019/10/15/KCnDqf.png)

For the same track (3D point) one image point provides 2 contraits. With 3 unknowns to solve for each point,
at least 2 image points of this track (2 camera views) has to be provided for a solution. If more than 2
views are available, least squares can be used. RANSAC can be introduced if outliers are present. Note that
in the RANSAC modelling process, reprojection error is used as an estimate for inliner/outlier.
![KCn6Ig.png](https://s2.ax1x.com/2019/10/15/KCn6Ig.png)

#### 2.4 Bundle Adjustment for the initial pair
With the calculated camera poses and the triangulated tracks, a bundle adjustment can be used to optimise the
overall system. 
[![KChfUI.png](https://s2.ax1x.com/2019/10/15/KChfUI.png)](https://imgchr.com/i/KChfUI)

### 3. Incrementally add new views 

#### 3.1 Workflow 
The process is shown in the following self-explained pseudo code.

_registered_images=2;<br>
image_stack=0;<br>
num_of_images_per_bundle=NUM; <br>
<br>
while (true) <br>{
     - With current available tracks , first load all the relevant images that haven't been reconstructed. <br>
     - Sort these views/images according to the number of tracks it contains in descent order. Pick the top image and try to reconstruct the view (pose calculation) using PnP. <br>
     - If current view/camera successfully reconstructed (3.2): { <br>
                                                                &nbsp; &nbsp; do a single camera based bundle adjustment (technique used in 2.4).  <br>
                                                                &nbsp;&nbsp; registered_images++; <br>
                                                                &nbsp;&nbsp; image_stack++; <br>
                                                                &nbsp;&nbsp; if image_stack==num_of_images_per_bundle: <br>
                                                                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; {triangulate all new tracks (technique used in 2.3); <br>
                                                                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  full bundle adjustment of all registered images (technique used in 2.4); <br>
                                                                &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  image_stack=0;} <br>
                                                                } <br>
     - If no new image is able to reconstruct :{ <br>
                                                               &nbsp;&nbsp; if image_stack=0 (all the registered images have been processed in Bundle Adjustment) break (terminate the SFM process and output result); <br>
                                                               &nbsp;&nbsp; if image_stack>0 (some new images have been registered but not bundle adjusted) full bundle adjustment on all the current registered images, image_stack=0; <br>
                                                               }_ <br>
                                                               
                            

#### 3.2 Calculate the pose for the new view
With the new image, we've now got several tracks with both 2D coordinates and 3D coordinates. We need to calculate the new
camera pose. This is a typical PnP problem. In computer vision its solution is _Projective Relation_ based while in photogrammetry
such problem is called space resection and solved based on _Collinearity Equation_. The following mainly shows the PnP approach: 
![KCTX9I.png](https://s2.ax1x.com/2019/10/15/KCTX9I.png)
Here a 3D point with both 3D coordinates, 2D image coordinates, provide 2 constraints. In the Projection Matrix, there are 11 DoF,
it therefore requires a minimum of 6 points to solve (DLT):  
[![KC7pDS.png](https://s2.ax1x.com/2019/10/15/KC7pDS.png)](https://imgchr.com/i/KC7pDS)
with [r1,r2,r3]^T calculated, the projection matrix can be obtained. If more than 6 points are known, least squares solution 
can be used. 

## Discussion
1. Advantages:<br>
   High precision in 3D reconstruction;<br>
   Robust to outliers; <br>
2. Disadvantages: <br>
   Sensitive to the initial pair selection and the order of views in the incremental process; <br>
   Easily accumulate errors in the incremental process, leading to the overall shift of the whole scene; <br>
   Low efficiency; <br>
3. Open source libraries:<br>
   <a href="https://www.cs.cornell.edu/~snavely/bundler/"> Bundler </a><br>
   <a href="http://ccwu.me/vsfm/install.html"> VisualSFM </a><br>
   <a href="http://theia-sfm.org/"> Theia </a><br>
   <a href="https://demuc.de/colmap/"> Colmap </a><br>
   